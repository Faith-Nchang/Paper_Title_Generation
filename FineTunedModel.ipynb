{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c403c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nchan\\Downloads\\Paper_Title_Generation\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c010af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "\n",
    "path = os.path.join('data', 'All_capped_keywords.csv')\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e71a528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['paperID', 'venue', 'year', 'openAccessPdf', 'url', 'authors', 'referenceCount', 'title', 'abstract', 'conclusion', 'Chatgpt Response', 'Key Takeaways', 'Importance', 'Model/Method Proposed', 'Performance', 'Effectiveness', 'Future Works', 'Sentiment', 'Sentiment Score', 'combined', 'combined_keywords', 'response_keywords', 'future_work_keywords', 'capped_keywords', 'field'],\n",
       "        num_rows: 82727\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['paperID', 'venue', 'year', 'openAccessPdf', 'url', 'authors', 'referenceCount', 'title', 'abstract', 'conclusion', 'Chatgpt Response', 'Key Takeaways', 'Importance', 'Model/Method Proposed', 'Performance', 'Effectiveness', 'Future Works', 'Sentiment', 'Sentiment Score', 'combined', 'combined_keywords', 'response_keywords', 'future_work_keywords', 'capped_keywords', 'field'],\n",
       "        num_rows: 9192\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train/test (90% train, 10% test)\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "\n",
    "# Convert to Hugging Face Dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "test_dataset = Dataset.from_pandas(test_df.reset_index(drop=True))\n",
    "\n",
    "# Create a DatasetDict like in the SFT notebook\n",
    "dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"test\": test_dataset\n",
    "})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc11c81b",
   "metadata": {},
   "source": [
    "### an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cd4f15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['paperID', 'venue', 'year', 'openAccessPdf', 'url', 'authors', 'referenceCount', 'title', 'abstract', 'conclusion', 'Chatgpt Response', 'Key Takeaways', 'Importance', 'Model/Method Proposed', 'Performance', 'Effectiveness', 'Future Works', 'Sentiment', 'Sentiment Score', 'combined', 'combined_keywords', 'response_keywords', 'future_work_keywords', 'capped_keywords', 'field'])\n"
     ]
    }
   ],
   "source": [
    "example = dataset[\"train\"][0]\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfda80a",
   "metadata": {},
   "source": [
    "### print the abstract from this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7456d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ambiguity is a major obstacle to providing services based on sentence classification. However, because of the structural limitations of the service, there may not be sufficient contextual information to resolve the ambiguity. In this situation, we focus on ambiguity detection so that service design considering ambiguity is possible. We utilize similarity in a semantic space to detect ambiguity in service scenarios and training data. In addition, we apply task-specific embedding to improve performance. Our results demonstrate that ambiguities and resulting labeling errors in training data or scenarios can be detected. Additionally, we confirm that it can be used to debug services\n"
     ]
    }
   ],
   "source": [
    "abstract = example[\"abstract\"]\n",
    "print(abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e3e296",
   "metadata": {},
   "source": [
    "### load the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c8c32bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce740e55",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model_id = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "# required for training\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Set reasonable max length for abstracts + titles\n",
    "if tokenizer.model_max_length > 100_000:\n",
    "    tokenizer.model_max_length = 600\n",
    "\n",
    "# Define a simple instruction template for supervised fine-tuning\n",
    "# The model input will be the abstract, output will be the title\n",
    "DEFAULT_TITLE_TEMPLATE = \"Abstract: {abstract}\\nTitle:\"\n",
    "\n",
    "tokenizer.title_template = DEFAULT_TITLE_TEMPLATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee85060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import random\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92f3af08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Applying article template (num_proc=8):   0%|          | 0/82727 [03:28<?, ? examples/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "One of the subprocesses has abruptly died during map operation.To debug the error, disable multiprocessing.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Remove other columns after creating the text\u001b[39;00m\n\u001b[32m      8\u001b[39m column_names = \u001b[38;5;28mlist\u001b[39m(dataset[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m].features)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m dataset = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapply_article_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcpu_count\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtokenizer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumn_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mApplying article template\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# create the splits\u001b[39;00m\n\u001b[32m     16\u001b[39m train_dataset = dataset[\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nchan\\Documents\\Playful_Paper_Title_Generation\\venv\\Lib\\site-packages\\datasets\\dataset_dict.py:946\u001b[39m, in \u001b[36mDatasetDict.map\u001b[39m\u001b[34m(self, function, with_indices, with_rank, with_split, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc, try_original_type)\u001b[39m\n\u001b[32m    943\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m with_split:\n\u001b[32m    944\u001b[39m     function = bind(function, split)\n\u001b[32m--> \u001b[39m\u001b[32m946\u001b[39m dataset_dict[split] = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    947\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    948\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    949\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    950\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    951\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    952\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    953\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    954\u001b[39m \u001b[43m    \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    955\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    956\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtry_original_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtry_original_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m with_split:\n\u001b[32m    968\u001b[39m     function = function.func\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nchan\\Documents\\Playful_Paper_Title_Generation\\venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:560\u001b[39m, in \u001b[36mtransmit_format.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    553\u001b[39m self_format = {\n\u001b[32m    554\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_type,\n\u001b[32m    555\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_kwargs\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_kwargs,\n\u001b[32m    556\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._format_columns,\n\u001b[32m    557\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33moutput_all_columns\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._output_all_columns,\n\u001b[32m    558\u001b[39m }\n\u001b[32m    559\u001b[39m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m560\u001b[39m out: Union[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDatasetDict\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    561\u001b[39m datasets: \u001b[38;5;28mlist\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33mDataset\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlist\u001b[39m(out.values()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[32m    562\u001b[39m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nchan\\Documents\\Playful_Paper_Title_Generation\\venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:3309\u001b[39m, in \u001b[36mDataset.map\u001b[39m\u001b[34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc, try_original_type)\u001b[39m\n\u001b[32m   3306\u001b[39m os.environ = prev_env\n\u001b[32m   3307\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSpawning \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m processes\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m3309\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miflatmap_unordered\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_map_single\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs_iterable\u001b[49m\u001b[43m=\u001b[49m\u001b[43munprocessed_kwargs_per_job\u001b[49m\n\u001b[32m   3311\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_if_shard_done\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3314\u001b[39m pool.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nchan\\Documents\\Playful_Paper_Title_Generation\\venv\\Lib\\site-packages\\datasets\\utils\\py_utils.py:619\u001b[39m, in \u001b[36miflatmap_unordered\u001b[39m\u001b[34m(pool, func, kwargs_iterable)\u001b[39m\n\u001b[32m    617\u001b[39m             pool_changed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    618\u001b[39m             \u001b[38;5;66;03m# One of the subprocesses has died. We should not wait forever.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    620\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mOne of the subprocesses has abruptly died during map operation.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    621\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mTo debug the error, disable multiprocessing.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    622\u001b[39m             )\n\u001b[32m    623\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    624\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pool_changed:\n\u001b[32m    625\u001b[39m         \u001b[38;5;66;03m# we get the result in case there's an error to raise\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: One of the subprocesses has abruptly died during map operation.To debug the error, disable multiprocessing."
     ]
    }
   ],
   "source": [
    "def apply_article_template(example, tokenizer):\n",
    "      \n",
    "    example[\"description\"] = f\"Abstract: {example['abstract']}\\nTitle: {example['title']}\"\n",
    "    return example\n",
    "\n",
    "\n",
    "# Remove other columns after creating the text\n",
    "column_names = list(dataset['train'].features)\n",
    "dataset = dataset.map(apply_article_template,\n",
    "                                num_proc=cpu_count(),\n",
    "                                fn_kwargs={\"tokenizer\": tokenizer},\n",
    "                                remove_columns=column_names,\n",
    "                                desc=\"Applying article template\",)\n",
    "\n",
    "# create the splits\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"test\"]\n",
    "\n",
    "for index in random.sample(range(len(dataset[\"train\"])), 3):\n",
    "  print(f\"Sample {index} of the processed training set:\\n\\n{dataset['train'][index]['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc41d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['description'],\n",
       "        num_rows: 82727\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['description'],\n",
       "        num_rows: 9192\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d661e5",
   "metadata": {},
   "source": [
    "### define the model arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9b4504",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "# specify how to quantize the model\n",
    "# quantization_config = BitsAndBytesConfig(\n",
    "#             load_in_4bit=True,\n",
    "#             bnb_4bit_quant_type=\"nf4\",\n",
    "#             bnb_4bit_compute_dtype=torch.float16,\n",
    "# )\n",
    "\n",
    "model_kwargs = dict(\n",
    "    torch_dtype=\"auto\",      # Auto will pick float32 on CPU\n",
    "    use_cache=False,         # Required for gradient checkpointing\n",
    "    device_map=None,         # CPU only\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97da0c46",
   "metadata": {},
   "source": [
    "### Define SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90cae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (4.56.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from transformers[torch]) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from transformers[torch]) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from transformers[torch]) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from transformers[torch]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from transformers[torch]) (2025.9.1)\n",
      "Requirement already satisfied: requests in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from transformers[torch]) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from transformers[torch]) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from transformers[torch]) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.2 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from transformers[torch]) (2.8.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from transformers[torch]) (1.10.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (4.15.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (7.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from torch>=2.2->transformers[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from torch>=2.2->transformers[torch]) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from torch>=2.2->transformers[torch]) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from torch>=2.2->transformers[torch]) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from jinja2->torch>=2.2->transformers[torch]) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from requests->transformers[torch]) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from requests->transformers[torch]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from requests->transformers[torch]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nchan\\documents\\playful_paper_title_generation\\venv\\lib\\site-packages (from requests->transformers[torch]) (2025.8.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 47\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# based on config\u001b[39;00m\n\u001b[32m     36\u001b[39m peft_config = LoraConfig(\n\u001b[32m     37\u001b[39m         r=\u001b[32m64\u001b[39m,\n\u001b[32m     38\u001b[39m         lora_alpha=\u001b[32m16\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m         target_modules=[\u001b[33m\"\u001b[39m\u001b[33mq_proj\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mk_proj\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mv_proj\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mo_proj\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m     43\u001b[39m )\n\u001b[32m     46\u001b[39m trainer = SFTTrainer(\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     model=\u001b[43mmodel_id\u001b[49m,\n\u001b[32m     48\u001b[39m     model_init_kwargs=model_kwargs,\n\u001b[32m     49\u001b[39m     args=training_args,\n\u001b[32m     50\u001b[39m     train_dataset=train_dataset,\n\u001b[32m     51\u001b[39m     eval_dataset=eval_dataset,\n\u001b[32m     52\u001b[39m     dataset_text_field=\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     53\u001b[39m     tokenizer=tokenizer,\n\u001b[32m     54\u001b[39m     packing=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     55\u001b[39m     peft_config=peft_config,\n\u001b[32m     56\u001b[39m     max_seq_length=tokenizer.model_max_length,\n\u001b[32m     57\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'model_id' is not defined"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from peft import LoraConfig\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# path where the Trainer will save its checkpoints and logs\n",
    "output_dir = 'data/article-t5-small'\n",
    "\n",
    "# based on config\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    fp16=False,                    # CPU \n",
    "    do_eval=True,\n",
    "    gradient_accumulation_steps=1, # Reduce accumulation on CPU\n",
    "    gradient_checkpointing=False,  \n",
    "    learning_rate=2e-5,\n",
    "    log_level=\"info\",\n",
    "    logging_steps=5,\n",
    "    logging_strategy=\"steps\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    max_steps=-1,\n",
    "    num_train_epochs=1,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=True,\n",
    "    per_device_train_batch_size=1, \n",
    "    per_device_eval_batch_size=1,\n",
    "    save_strategy=\"no\",\n",
    "    save_total_limit=None,\n",
    "    seed=42,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# based on config\n",
    "peft_config = LoraConfig(\n",
    "        r=64,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.1,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n",
    ")\n",
    "\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model_id,\n",
    "    model_init_kwargs=model_kwargs,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    packing=True,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length=tokenizer.model_max_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fce005",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b8ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b385e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a84d1cd5",
   "metadata": {},
   "source": [
    "### save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021cd53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = train_result.metrics\n",
    "max_train_samples = training_args.max_train_samples if training_args.max_train_samples is not None else len(train_dataset)\n",
    "metrics[\"train_samples\"] = min(max_train_samples, len(train_dataset))\n",
    "trainer.log_metrics(\"train\", metrics)\n",
    "trainer.save_metrics(\"train\", metrics)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16de051c",
   "metadata": {},
   "source": [
    "### use the saved model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed82b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(output_dir, load_in_4bit=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c129a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "title = \"Are Individual's political ideologies impacted by the surrounding environment\"\n",
    "\n",
    "# prepare the messages for the model\n",
    "input_ids = tokenizer.apply_article_template(title, truncation=True, add_generation_prompt=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "# inference\n",
    "outputs = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_k=50,\n",
    "        top_p=0.95\n",
    ")\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb50a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
